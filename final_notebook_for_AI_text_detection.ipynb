{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["<!-- # This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session -->"]},{"cell_type":"markdown","metadata":{},"source":["# ***AI TEXT DETECTION*** "]},{"cell_type":"markdown","metadata":{},"source":["## Let us load and visualize the dataset "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:07.621705Z","iopub.status.busy":"2024-01-14T11:35:07.621431Z","iopub.status.idle":"2024-01-14T11:35:08.092985Z","shell.execute_reply":"2024-01-14T11:35:08.092129Z","shell.execute_reply.started":"2024-01-14T11:35:07.621681Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","dataset = pd.read_csv(\"../input/llm-detect-ai-generated-text/train_essays.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:08.094390Z","iopub.status.busy":"2024-01-14T11:35:08.094097Z","iopub.status.idle":"2024-01-14T11:35:08.113056Z","shell.execute_reply":"2024-01-14T11:35:08.112162Z","shell.execute_reply.started":"2024-01-14T11:35:08.094365Z"},"trusted":true},"outputs":[],"source":["dataset.head() #here 0 ---> human and 1--> generated "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:08.126707Z","iopub.status.busy":"2024-01-14T11:35:08.126300Z","iopub.status.idle":"2024-01-14T11:35:08.136343Z","shell.execute_reply":"2024-01-14T11:35:08.135368Z","shell.execute_reply.started":"2024-01-14T11:35:08.126661Z"},"trusted":true},"outputs":[],"source":["#check the shape of the dataset for the number of entries\n","dataset.shape "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:08.139941Z","iopub.status.busy":"2024-01-14T11:35:08.139592Z","iopub.status.idle":"2024-01-14T11:35:08.148990Z","shell.execute_reply":"2024-01-14T11:35:08.148120Z","shell.execute_reply.started":"2024-01-14T11:35:08.139915Z"},"trusted":true},"outputs":[],"source":["#We have 1378 entries \n","\n","#We have no need for the 'id' and the 'prompt_id' columns --> remove them\n","del dataset['id'], dataset['prompt_id']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:08.150413Z","iopub.status.busy":"2024-01-14T11:35:08.150137Z","iopub.status.idle":"2024-01-14T11:35:08.476213Z","shell.execute_reply":"2024-01-14T11:35:08.475144Z","shell.execute_reply.started":"2024-01-14T11:35:08.150389Z"},"trusted":true},"outputs":[],"source":["# Now that we know the no. of entries, let's see the distribution of the data \n","import matplotlib.pyplot as plt\n","\n","dataset['generated'].value_counts(ascending=True).plot.bar()\n","plt.title(\"Data distribution\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-01-09T17:21:58.539087Z","iopub.status.busy":"2024-01-09T17:21:58.538671Z","iopub.status.idle":"2024-01-09T17:21:58.543550Z","shell.execute_reply":"2024-01-09T17:21:58.542512Z","shell.execute_reply.started":"2024-01-09T17:21:58.539054Z"}},"source":["Here we can see that human written data is much more than the AI-generated text, \n","that means that the dataset is imbalanced, \n","so we need the external data that we downloaded earlier"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:08.478123Z","iopub.status.busy":"2024-01-14T11:35:08.477720Z","iopub.status.idle":"2024-01-14T11:35:11.007915Z","shell.execute_reply":"2024-01-14T11:35:11.006685Z","shell.execute_reply.started":"2024-01-14T11:35:08.478069Z"},"trusted":true},"outputs":[],"source":["# Let's load the external dataset that we have downloaded\n","external_dataset = pd.read_csv(\"../input/ai-text-detection-dataset/external_dataset.csv\")\n","external_dataset.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:11.010065Z","iopub.status.busy":"2024-01-14T11:35:11.009665Z","iopub.status.idle":"2024-01-14T11:35:11.017340Z","shell.execute_reply":"2024-01-14T11:35:11.016141Z","shell.execute_reply.started":"2024-01-14T11:35:11.010027Z"},"trusted":true},"outputs":[],"source":["#Let's check the number of entries in the external dataset \n","external_dataset.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:11.019233Z","iopub.status.busy":"2024-01-14T11:35:11.018829Z","iopub.status.idle":"2024-01-14T11:35:11.030549Z","shell.execute_reply":"2024-01-14T11:35:11.029511Z","shell.execute_reply.started":"2024-01-14T11:35:11.019201Z"},"trusted":true},"outputs":[],"source":["#Let's combine both the datasets \n","complete_df = pd.concat([dataset,external_dataset])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:11.032591Z","iopub.status.busy":"2024-01-14T11:35:11.032181Z","iopub.status.idle":"2024-01-14T11:35:11.047913Z","shell.execute_reply":"2024-01-14T11:35:11.047137Z","shell.execute_reply.started":"2024-01-14T11:35:11.032552Z"},"trusted":true},"outputs":[],"source":["complete_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:11.050093Z","iopub.status.busy":"2024-01-14T11:35:11.049694Z","iopub.status.idle":"2024-01-14T11:35:11.138628Z","shell.execute_reply":"2024-01-14T11:35:11.137499Z","shell.execute_reply.started":"2024-01-14T11:35:11.050039Z"},"trusted":true},"outputs":[],"source":["#Let's remove the duplicate entries(if any) and check the number of entries\n","complete_df.drop_duplicates(subset=['text'], inplace=True)\n","complete_df.reset_index(drop=True, inplace=True)\n","complete_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:11.141422Z","iopub.status.busy":"2024-01-14T11:35:11.141007Z","iopub.status.idle":"2024-01-14T11:35:11.403938Z","shell.execute_reply":"2024-01-14T11:35:11.403013Z","shell.execute_reply.started":"2024-01-14T11:35:11.141385Z"},"trusted":true},"outputs":[],"source":["#Now, let us see the distribution of the new data obtained \n","complete_df['generated'].value_counts(ascending=True).plot.bar()\n","plt.title(\"Data distribution\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-01-09T17:30:06.336095Z","iopub.status.busy":"2024-01-09T17:30:06.335691Z","iopub.status.idle":"2024-01-09T17:30:06.340397Z","shell.execute_reply":"2024-01-09T17:30:06.339473Z","shell.execute_reply.started":"2024-01-09T17:30:06.336062Z"}},"source":["Even now the data is somewhat imbalanced, but this is ok, \n","we have double the human written text than the AI generated text."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:11.405592Z","iopub.status.busy":"2024-01-14T11:35:11.405234Z","iopub.status.idle":"2024-01-14T11:35:13.977547Z","shell.execute_reply":"2024-01-14T11:35:13.976637Z","shell.execute_reply.started":"2024-01-14T11:35:11.405556Z"},"trusted":true},"outputs":[],"source":["#Let's add a new column to check the words per para for each entry\n","complete_df['Words per para'] = complete_df['text'].str.split().apply(len)\n","complete_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:13.979173Z","iopub.status.busy":"2024-01-14T11:35:13.978804Z","iopub.status.idle":"2024-01-14T11:35:14.369541Z","shell.execute_reply":"2024-01-14T11:35:14.368577Z","shell.execute_reply.started":"2024-01-14T11:35:13.979138Z"},"trusted":true},"outputs":[],"source":["#Let us visualize this newly generated column using a box-plot \n","complete_df.boxplot(figsize=(7,7), column='Words per para', by='generated',showfliers=False, color='blue')"]},{"cell_type":"markdown","metadata":{},"source":["From the above boxplot, it can be clearly seen that the average 'Words per para' for both the categories are very near. Also, the maximum percentage of the data lies between 300-500 words."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:14.371001Z","iopub.status.busy":"2024-01-14T11:35:14.370707Z","iopub.status.idle":"2024-01-14T11:35:14.733893Z","shell.execute_reply":"2024-01-14T11:35:14.732965Z","shell.execute_reply.started":"2024-01-14T11:35:14.370960Z"},"trusted":true},"outputs":[],"source":["#Let us visualize this newly generated column using another box-plot \n","complete_df.boxplot(figsize=(10,15), column='Words per para',showfliers=True, color='blue')"]},{"cell_type":"markdown","metadata":{},"source":["Let us remove the outliers, ie the entries with more than 800 words per para to be removed"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:14.737987Z","iopub.status.busy":"2024-01-14T11:35:14.737597Z","iopub.status.idle":"2024-01-14T11:35:14.747186Z","shell.execute_reply":"2024-01-14T11:35:14.746346Z","shell.execute_reply.started":"2024-01-14T11:35:14.737960Z"},"trusted":true},"outputs":[],"source":["complete_df = complete_df[complete_df['Words per para'] <= 800]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:14.749599Z","iopub.status.busy":"2024-01-14T11:35:14.748651Z","iopub.status.idle":"2024-01-14T11:35:15.065045Z","shell.execute_reply":"2024-01-14T11:35:15.064049Z","shell.execute_reply.started":"2024-01-14T11:35:14.749557Z"},"trusted":true},"outputs":[],"source":["#Now, let us see the distribution of the new data obtained \n","complete_df['generated'].value_counts(ascending=True).plot.bar()\n","plt.title(\"Data distribution\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:15.073576Z","iopub.status.busy":"2024-01-14T11:35:15.072710Z","iopub.status.idle":"2024-01-14T11:35:15.079624Z","shell.execute_reply":"2024-01-14T11:35:15.078244Z","shell.execute_reply.started":"2024-01-14T11:35:15.073547Z"},"trusted":true},"outputs":[],"source":["#Now since there is no need for the 'words per para' column, so let's drop this column\n","del complete_df['Words per para']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:15.081670Z","iopub.status.busy":"2024-01-14T11:35:15.081215Z","iopub.status.idle":"2024-01-14T11:35:15.093795Z","shell.execute_reply":"2024-01-14T11:35:15.092707Z","shell.execute_reply.started":"2024-01-14T11:35:15.081630Z"},"trusted":true},"outputs":[],"source":["# Rename the column 'generated' to 'label'\n","complete_df = complete_df.rename(columns={'generated': 'label'})"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocessing of the data(to feed to the model) "]},{"cell_type":"markdown","metadata":{},"source":["### Converting the above datasets into a hugging face dataset object "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:15.102991Z","iopub.status.busy":"2024-01-14T11:35:15.102577Z","iopub.status.idle":"2024-01-14T11:35:16.847703Z","shell.execute_reply":"2024-01-14T11:35:16.846877Z","shell.execute_reply.started":"2024-01-14T11:35:15.102964Z"},"trusted":true},"outputs":[],"source":["#import the required libraries\n","from sklearn.model_selection import train_test_split\n","from datasets import Dataset, DatasetDict\n","\n","#split the data into training and validation dataset\n","train_dataset, valid_dataset = train_test_split(complete_df, test_size = 0.30, random_state = 10) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:16.849785Z","iopub.status.busy":"2024-01-14T11:35:16.849311Z","iopub.status.idle":"2024-01-14T11:35:16.855903Z","shell.execute_reply":"2024-01-14T11:35:16.854724Z","shell.execute_reply.started":"2024-01-14T11:35:16.849757Z"},"trusted":true},"outputs":[],"source":["train_dataset.shape, valid_dataset.shape "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:16.857361Z","iopub.status.busy":"2024-01-14T11:35:16.857101Z","iopub.status.idle":"2024-01-14T11:35:17.121896Z","shell.execute_reply":"2024-01-14T11:35:17.120944Z","shell.execute_reply.started":"2024-01-14T11:35:16.857338Z"},"trusted":true},"outputs":[],"source":["#Convert the train_dataset and the valid_dataset into Dataset objects\n","train_data = Dataset.from_pandas(train_dataset)\n","valid_data = Dataset.from_pandas(valid_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:17.123279Z","iopub.status.busy":"2024-01-14T11:35:17.122990Z","iopub.status.idle":"2024-01-14T11:35:17.128703Z","shell.execute_reply":"2024-01-14T11:35:17.127815Z","shell.execute_reply.started":"2024-01-14T11:35:17.123253Z"},"trusted":true},"outputs":[],"source":["#Create a DatasetDict\n","comp_data= DatasetDict({\"train\": train_data, \"valid\": valid_data})\n","\n","print(comp_data)"]},{"cell_type":"markdown","metadata":{},"source":["### Conversion of the text to tokens "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:17.130062Z","iopub.status.busy":"2024-01-14T11:35:17.129817Z","iopub.status.idle":"2024-01-14T11:35:23.088700Z","shell.execute_reply":"2024-01-14T11:35:23.087653Z","shell.execute_reply.started":"2024-01-14T11:35:17.130040Z"},"trusted":true},"outputs":[],"source":["# We will be using a sub-word tokenizer to tokenize the text that we have using the tokenizer for the roberta-base\n","from transformers import AutoTokenizer\n","# model_checkpoint = \"roberta-base\"\n","model_checkpoint = '../input/roberta-pretrained-model-with-classification-head/roberta_base_without_classification_head/content/roberta_base'\n","\n","#load the tokenizer from the model checkpoint\n","text_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:23.090855Z","iopub.status.busy":"2024-01-14T11:35:23.090223Z","iopub.status.idle":"2024-01-14T11:35:23.097312Z","shell.execute_reply":"2024-01-14T11:35:23.096316Z","shell.execute_reply.started":"2024-01-14T11:35:23.090818Z"},"trusted":true},"outputs":[],"source":["#Let us check the maximum content size of this tokenizer(the maximum no. of tokens per entry)\n","text_tokenizer.model_max_length"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:23.099197Z","iopub.status.busy":"2024-01-14T11:35:23.098817Z","iopub.status.idle":"2024-01-14T11:35:23.110477Z","shell.execute_reply":"2024-01-14T11:35:23.109577Z","shell.execute_reply.started":"2024-01-14T11:35:23.099164Z"},"trusted":true},"outputs":[],"source":["#Let's us check an entry using this \n","complete_df['text'][0] #the number of words in this entry were 584"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:23.111934Z","iopub.status.busy":"2024-01-14T11:35:23.111546Z","iopub.status.idle":"2024-01-14T11:35:23.129133Z","shell.execute_reply":"2024-01-14T11:35:23.128363Z","shell.execute_reply.started":"2024-01-14T11:35:23.111909Z"},"trusted":true},"outputs":[],"source":["encoded_text = text_tokenizer(complete_df['text'][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:23.130393Z","iopub.status.busy":"2024-01-14T11:35:23.130141Z","iopub.status.idle":"2024-01-14T11:35:23.136951Z","shell.execute_reply":"2024-01-14T11:35:23.135936Z","shell.execute_reply.started":"2024-01-14T11:35:23.130371Z"},"trusted":true},"outputs":[],"source":["len(encoded_text['input_ids']) #the number of tokens has exceeded the number of maximum tokens --> this means we will have to truncate those tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:23.138810Z","iopub.status.busy":"2024-01-14T11:35:23.138200Z","iopub.status.idle":"2024-01-14T11:35:23.145107Z","shell.execute_reply":"2024-01-14T11:35:23.144257Z","shell.execute_reply.started":"2024-01-14T11:35:23.138776Z"},"trusted":true},"outputs":[],"source":["#define a function to apply tokenization on all the entries\n","def tokenize_text(input_entry):\n","    #we also apply padding, in case the tokens remain less than 512\n","    return text_tokenizer(input_entry['text'], padding=True, truncation = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:35:23.147212Z","iopub.status.busy":"2024-01-14T11:35:23.146382Z","iopub.status.idle":"2024-01-14T11:36:00.274547Z","shell.execute_reply":"2024-01-14T11:36:00.273699Z","shell.execute_reply.started":"2024-01-14T11:35:23.147175Z"},"trusted":true},"outputs":[],"source":["#Apply to all the dataset as a single batch since the batch_size is given as none\n","comp_tokenized_data = comp_data.map(tokenize_text , batched = True , batch_size = None)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:36:00.277177Z","iopub.status.busy":"2024-01-14T11:36:00.276855Z","iopub.status.idle":"2024-01-14T11:36:00.283437Z","shell.execute_reply":"2024-01-14T11:36:00.282440Z","shell.execute_reply.started":"2024-01-14T11:36:00.277150Z"},"trusted":true},"outputs":[],"source":["comp_tokenized_data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:36:00.285346Z","iopub.status.busy":"2024-01-14T11:36:00.285041Z","iopub.status.idle":"2024-01-14T11:36:00.296604Z","shell.execute_reply":"2024-01-14T11:36:00.295731Z","shell.execute_reply.started":"2024-01-14T11:36:00.285321Z"},"trusted":true},"outputs":[],"source":["comp_tokenized_data['train'].column_names"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:36:00.298013Z","iopub.status.busy":"2024-01-14T11:36:00.297666Z","iopub.status.idle":"2024-01-14T11:36:00.308866Z","shell.execute_reply":"2024-01-14T11:36:00.307910Z","shell.execute_reply.started":"2024-01-14T11:36:00.297987Z"},"trusted":true},"outputs":[],"source":["text_tokenizer.model_input_names"]},{"cell_type":"markdown","metadata":{},"source":["## Loading and training the model"]},{"cell_type":"markdown","metadata":{},"source":["### Loading a pre-trained model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:36:00.311038Z","iopub.status.busy":"2024-01-14T11:36:00.310288Z","iopub.status.idle":"2024-01-14T11:36:04.651303Z","shell.execute_reply":"2024-01-14T11:36:04.650376Z","shell.execute_reply.started":"2024-01-14T11:36:00.311004Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification\n","#We are using AutoModelForSequenceClassification --> because we want to do classification and using this,\n","#it automatically adds a classification head to the pretrained-model\n","#The classification has random weights assigned to it\n","\n","#Check for GPU, if available\n","import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","#Define the number of labels for the classification head(here we have 2 labels)\n","num_labels = 2\n","\n","#load the model and chain the model to gpu\n","model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels = num_labels).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:36:04.652808Z","iopub.status.busy":"2024-01-14T11:36:04.652506Z","iopub.status.idle":"2024-01-14T11:36:04.658436Z","shell.execute_reply":"2024-01-14T11:36:04.657436Z","shell.execute_reply.started":"2024-01-14T11:36:04.652784Z"},"trusted":true},"outputs":[],"source":["#define tne metrics function to compute the metrics\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    f1 = f1_score(labels, preds, average=\"weighted\")\n","    acc = accuracy_score(labels,preds)\n","    return {\"accuracy\":acc, \"f1\":f1}"]},{"cell_type":"markdown","metadata":{},"source":["### Defining the training arguments and the training object"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:36:04.659905Z","iopub.status.busy":"2024-01-14T11:36:04.659637Z","iopub.status.idle":"2024-01-14T11:36:04.683059Z","shell.execute_reply":"2024-01-14T11:36:04.682147Z","shell.execute_reply.started":"2024-01-14T11:36:04.659882Z"},"trusted":true},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","#define the batch size\n","batch_size = 16\n","\n","#define the logging steps so that we can define when to save the checkpoints\n","# logging_steps = (len(comp_tokenized_data['train'])) // batch_size\n","\n","model_name = \"LLM_AI_TEXT_DETECTOR_ROBERTA\"\n","\n","#define the training arguments\n","training_arguments = TrainingArguments(output_dir = model_name,\n","                                      num_train_epochs = 10,\n","                                      learning_rate = 1e-5,\n","                                      per_device_train_batch_size = batch_size,\n","                                      per_device_eval_batch_size = batch_size,\n","                                      weight_decay = 0.01,\n","                                      evaluation_strategy = \"epoch\",\n","                                      disable_tqdm = False,\n","                                      logging_steps = 4000,\n","                                      push_to_hub=False,\n","                                      report_to=\"none\",\n","                                      log_level='error',\n","                                      save_strategy = 'no')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:36:04.684519Z","iopub.status.busy":"2024-01-14T11:36:04.684241Z","iopub.status.idle":"2024-01-14T11:36:15.803883Z","shell.execute_reply":"2024-01-14T11:36:15.802919Z","shell.execute_reply.started":"2024-01-14T11:36:04.684494Z"},"trusted":true},"outputs":[],"source":["from transformers import Trainer\n","\n","trainer = Trainer(model= model, args = training_arguments,\n","                  compute_metrics=compute_metrics,\n","                  train_dataset= comp_tokenized_data['train'],\n","                  eval_dataset = comp_tokenized_data['valid'],\n","                  tokenizer=text_tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T11:36:15.805714Z","iopub.status.busy":"2024-01-14T11:36:15.805141Z","iopub.status.idle":"2024-01-14T11:44:56.618045Z","shell.execute_reply":"2024-01-14T11:44:56.616011Z","shell.execute_reply.started":"2024-01-14T11:36:15.805686Z"},"trusted":true},"outputs":[],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["### Doing some interference "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.618981Z","iopub.status.idle":"2024-01-14T11:44:56.619356Z","shell.execute_reply":"2024-01-14T11:44:56.619200Z","shell.execute_reply.started":"2024-01-14T11:44:56.619183Z"},"trusted":true},"outputs":[],"source":["pred_output_valid = trainer.predict(comp_tokenized_data['valid'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.621258Z","iopub.status.idle":"2024-01-14T11:44:56.621743Z","shell.execute_reply":"2024-01-14T11:44:56.621519Z","shell.execute_reply.started":"2024-01-14T11:44:56.621497Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","y_pred_valid = np.argmax(pred_output_valid.predictions, axis = 1)\n","y_pred_valid"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.623280Z","iopub.status.idle":"2024-01-14T11:44:56.623745Z","shell.execute_reply":"2024-01-14T11:44:56.623525Z","shell.execute_reply.started":"2024-01-14T11:44:56.623503Z"},"trusted":true},"outputs":[],"source":["#Let us create a confusion matrix for the interferences\n","\n","from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n","\n","def plot_confusion_matrix(y_preds, y_true, labels):\n","    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n","    fig, ax = plt.subplots(figsize=(6, 6))\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n","    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n","    plt.title(\"Normalized confusion matrix\")\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.624863Z","iopub.status.idle":"2024-01-14T11:44:56.625340Z","shell.execute_reply":"2024-01-14T11:44:56.625123Z","shell.execute_reply.started":"2024-01-14T11:44:56.625099Z"},"trusted":true},"outputs":[],"source":["y_valid = comp_tokenized_data['valid']['label']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.627894Z","iopub.status.idle":"2024-01-14T11:44:56.628842Z","shell.execute_reply":"2024-01-14T11:44:56.628607Z","shell.execute_reply.started":"2024-01-14T11:44:56.628583Z"},"trusted":true},"outputs":[],"source":["plot_confusion_matrix(y_pred_valid, y_valid, ['AI','Human'])"]},{"cell_type":"markdown","metadata":{},"source":["## Load the test dataset and make the predictions "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.630110Z","iopub.status.idle":"2024-01-14T11:44:56.631034Z","shell.execute_reply":"2024-01-14T11:44:56.630801Z","shell.execute_reply.started":"2024-01-14T11:44:56.630778Z"},"trusted":true},"outputs":[],"source":["test_dataset = pd.read_csv(\"../input/llm-detect-ai-generated-text/test_essays.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.632562Z","iopub.status.idle":"2024-01-14T11:44:56.633040Z","shell.execute_reply":"2024-01-14T11:44:56.632813Z","shell.execute_reply.started":"2024-01-14T11:44:56.632790Z"},"trusted":true},"outputs":[],"source":["test_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.634676Z","iopub.status.idle":"2024-01-14T11:44:56.635183Z","shell.execute_reply":"2024-01-14T11:44:56.634940Z","shell.execute_reply.started":"2024-01-14T11:44:56.634916Z"},"trusted":true},"outputs":[],"source":["#remove the prompt_id column from the dataset \n","del test_dataset['prompt_id']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.636385Z","iopub.status.idle":"2024-01-14T11:44:56.636847Z","shell.execute_reply":"2024-01-14T11:44:56.636626Z","shell.execute_reply.started":"2024-01-14T11:44:56.636604Z"},"trusted":true},"outputs":[],"source":["test_dataset_tokenize = test_dataset.copy()\n","del test_dataset_tokenize['id']\n","\n","#Convert the test_dataset into Dataset object\n","test_dataset_tokenize = Dataset.from_pandas(test_dataset_tokenize)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.638278Z","iopub.status.idle":"2024-01-14T11:44:56.638739Z","shell.execute_reply":"2024-01-14T11:44:56.638520Z","shell.execute_reply.started":"2024-01-14T11:44:56.638498Z"},"trusted":true},"outputs":[],"source":["test_dataset_tokenize "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.639696Z","iopub.status.idle":"2024-01-14T11:44:56.640175Z","shell.execute_reply":"2024-01-14T11:44:56.639943Z","shell.execute_reply.started":"2024-01-14T11:44:56.639921Z"},"trusted":true},"outputs":[],"source":["#Apply to all the dataset as a single batch since the batch_size is given as none\n","tokenized_test_data = test_dataset_tokenize.map(tokenize_text , batched = True , batch_size = None)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.641186Z","iopub.status.idle":"2024-01-14T11:44:56.641651Z","shell.execute_reply":"2024-01-14T11:44:56.641437Z","shell.execute_reply.started":"2024-01-14T11:44:56.641413Z"},"trusted":true},"outputs":[],"source":["tokenized_test_data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.642959Z","iopub.status.idle":"2024-01-14T11:44:56.643424Z","shell.execute_reply":"2024-01-14T11:44:56.643220Z","shell.execute_reply.started":"2024-01-14T11:44:56.643199Z"},"trusted":true},"outputs":[],"source":["pred_output_test = trainer.predict(tokenized_test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.644836Z","iopub.status.idle":"2024-01-14T11:44:56.645293Z","shell.execute_reply":"2024-01-14T11:44:56.645069Z","shell.execute_reply.started":"2024-01-14T11:44:56.645047Z"},"trusted":true},"outputs":[],"source":["pred_output_test.predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.648146Z","iopub.status.idle":"2024-01-14T11:44:56.648618Z","shell.execute_reply":"2024-01-14T11:44:56.648403Z","shell.execute_reply.started":"2024-01-14T11:44:56.648381Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","\n","probabilities = F.softmax(torch.from_numpy(pred_output_test.predictions), dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.650302Z","iopub.status.idle":"2024-01-14T11:44:56.650790Z","shell.execute_reply":"2024-01-14T11:44:56.650575Z","shell.execute_reply.started":"2024-01-14T11:44:56.650552Z"},"trusted":true},"outputs":[],"source":["#convert back to numpy \n","probabilities = probabilities.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.652607Z","iopub.status.idle":"2024-01-14T11:44:56.653491Z","shell.execute_reply":"2024-01-14T11:44:56.653252Z","shell.execute_reply.started":"2024-01-14T11:44:56.653227Z"},"trusted":true},"outputs":[],"source":["ai_generated_probabilities = probabilities[:, 1].tolist()\n","ai_generated_probabilities"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.654754Z","iopub.status.idle":"2024-01-14T11:44:56.655731Z","shell.execute_reply":"2024-01-14T11:44:56.655500Z","shell.execute_reply.started":"2024-01-14T11:44:56.655476Z"},"trusted":true},"outputs":[],"source":["#add the 'generated' column and delete the 'text' column\n","test_dataset['generated'] = ai_generated_probabilities\n","del test_dataset['text']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.661665Z","iopub.status.idle":"2024-01-14T11:44:56.662338Z","shell.execute_reply":"2024-01-14T11:44:56.662128Z","shell.execute_reply.started":"2024-01-14T11:44:56.662106Z"},"trusted":true},"outputs":[],"source":["test_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T11:44:56.663390Z","iopub.status.idle":"2024-01-14T11:44:56.663803Z","shell.execute_reply":"2024-01-14T11:44:56.663608Z","shell.execute_reply.started":"2024-01-14T11:44:56.663588Z"},"trusted":true},"outputs":[],"source":["#create the submission file\n","test_dataset.to_csv('submission.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":6888007,"sourceId":61542,"sourceType":"competition"},{"datasetId":4285287,"sourceId":7374955,"sourceType":"datasetVersion"},{"datasetId":4292267,"sourceId":7391940,"sourceType":"datasetVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
